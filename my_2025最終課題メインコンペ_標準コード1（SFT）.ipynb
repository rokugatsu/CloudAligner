{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4ef72adfe7144cea4026a7ee5ce5eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_fb4cf5dbac3a4556b931cde596a3ea1f"
          }
        },
        "e41827c8bcad44a4b590132cc3d93158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7618cc47eaf84261921c7ef2b682d70a",
            "placeholder": "​",
            "style": "IPY_MODEL_61036b8ddb0c4780bbb1665835d4d0bc",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "babceeed66bb48149fcca7c3fd6ea94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b0a3e3503cc849a5af5eefa293a463b2",
            "placeholder": "​",
            "style": "IPY_MODEL_30b2f3e22da845039f1d0970f12abaf6",
            "value": ""
          }
        },
        "ad6e7214efec4e6c9f5245a4781b7a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_d57fb9b2be1144bf904f18bd49b48b89",
            "style": "IPY_MODEL_7c845d7ee87b4a9e8e5d4c15b49f5054",
            "value": true
          }
        },
        "084eb9599045475990a5183796230970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_660b373f49e84cf09c6e2b237a90d8c4",
            "style": "IPY_MODEL_7e57dee6bf9748038df40c2c0befc2f3",
            "tooltip": ""
          }
        },
        "b3abce898fb840bca8e0420ff455dcd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8b0ac1decb452f9c58dedbfecabcd7",
            "placeholder": "​",
            "style": "IPY_MODEL_d77e2ddcaab94b4ea4701a6cef58a228",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "fb4cf5dbac3a4556b931cde596a3ea1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "7618cc47eaf84261921c7ef2b682d70a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61036b8ddb0c4780bbb1665835d4d0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0a3e3503cc849a5af5eefa293a463b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b2f3e22da845039f1d0970f12abaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d57fb9b2be1144bf904f18bd49b48b89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c845d7ee87b4a9e8e5d4c15b49f5054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "660b373f49e84cf09c6e2b237a90d8c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e57dee6bf9748038df40c2c0befc2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3c8b0ac1decb452f9c58dedbfecabcd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d77e2ddcaab94b4ea4701a6cef58a228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cdc414dac904890bdb8965558bf1406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1900604cee784b81a197b3be87f40805",
            "placeholder": "​",
            "style": "IPY_MODEL_f8700cdd266b4501a4ab8c2e6276137b",
            "value": "Connecting..."
          }
        },
        "1900604cee784b81a197b3be87f40805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8700cdd266b4501a4ab8c2e6276137b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1bc8aaa7bf846e4b020aa59501894f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50d02cf203e34dc7a2ebc9a8f580f1a1",
              "IPY_MODEL_246aee554db34dc8a86212c9e77852e1",
              "IPY_MODEL_05c63df112444b0eb2b20989e6161f9e"
            ],
            "layout": "IPY_MODEL_45dff47faef64f24ac5fce0f82401155"
          }
        },
        "50d02cf203e34dc7a2ebc9a8f580f1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a58677a754284a7daca3b2a2918b9ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_efc43c4de1db4f2e9835b177e73de74d",
            "value": "Processing Files (2 / 2)      : 100%"
          }
        },
        "246aee554db34dc8a86212c9e77852e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669662156b4345019fb6b91c0a5b6920",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0aed939fb604203a240be4a771aba8f",
            "value": 1
          }
        },
        "05c63df112444b0eb2b20989e6161f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9714da820f72400b8168270abd7a8a3c",
            "placeholder": "​",
            "style": "IPY_MODEL_b2e9b2b0a4394797a98e060a2e00bf20",
            "value": "  540MB /  540MB, 75.5MB/s  "
          }
        },
        "45dff47faef64f24ac5fce0f82401155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a58677a754284a7daca3b2a2918b9ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efc43c4de1db4f2e9835b177e73de74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "669662156b4345019fb6b91c0a5b6920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b0aed939fb604203a240be4a771aba8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9714da820f72400b8168270abd7a8a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e9b2b0a4394797a98e060a2e00bf20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dbd5337cedb4c4f949bcdd13fa9f9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b3781a1ced0472f9b5519af9f9369a6",
              "IPY_MODEL_31ecfd13c34e401593114ae25bb36ad8",
              "IPY_MODEL_38e9f29b06864ae29b7912c3066a2b92"
            ],
            "layout": "IPY_MODEL_3c9539ff41274436b6ba9b1cbd8a6025"
          }
        },
        "3b3781a1ced0472f9b5519af9f9369a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad2350bb9dc495fac40bf057a2264e4",
            "placeholder": "​",
            "style": "IPY_MODEL_edba282cc2104b469458d52472bf8946",
            "value": "New Data Upload               : 100%"
          }
        },
        "31ecfd13c34e401593114ae25bb36ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_709f37b5f25842988485732b92cbdf3f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a30308b433414158827f01ef2752e08d",
            "value": 1
          }
        },
        "38e9f29b06864ae29b7912c3066a2b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e35a5c272ac493fb7e4e4e9c524315d",
            "placeholder": "​",
            "style": "IPY_MODEL_186d81ba39dc4b4cb27b665c9882de36",
            "value": "  528MB /  528MB, 75.5MB/s  "
          }
        },
        "3c9539ff41274436b6ba9b1cbd8a6025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad2350bb9dc495fac40bf057a2264e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edba282cc2104b469458d52472bf8946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "709f37b5f25842988485732b92cbdf3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a30308b433414158827f01ef2752e08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e35a5c272ac493fb7e4e4e9c524315d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186d81ba39dc4b4cb27b665c9882de36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14c1686cbd4d4564a9dbff4899411135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e928d2b206647998d2f389b3581c6fc",
              "IPY_MODEL_f57af96717944e2783ebd63adc94acdf",
              "IPY_MODEL_814a03905f044c03ac14767a0fa747c6"
            ],
            "layout": "IPY_MODEL_8ab0014db62c4ef4a87974d70e6b0bfd"
          }
        },
        "5e928d2b206647998d2f389b3581c6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82a16667ca6045edb144d65ec146594e",
            "placeholder": "​",
            "style": "IPY_MODEL_f83fb8df5456462d96dba8830672871f",
            "value": "  ...load_stage/tokenizer.json: 100%"
          }
        },
        "f57af96717944e2783ebd63adc94acdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fdb3cb464c84d7b9c8caa24b1cd1cf9",
            "max": 11422654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c24a0e5f9f644f29f73fc3d6de5a74c",
            "value": 11422654
          }
        },
        "814a03905f044c03ac14767a0fa747c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_659048492a0a43aab019da18cc0db4d2",
            "placeholder": "​",
            "style": "IPY_MODEL_1daec5231e9c4592b06f0a76592ea1e4",
            "value": " 11.4MB / 11.4MB            "
          }
        },
        "8ab0014db62c4ef4a87974d70e6b0bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a16667ca6045edb144d65ec146594e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83fb8df5456462d96dba8830672871f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fdb3cb464c84d7b9c8caa24b1cd1cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c24a0e5f9f644f29f73fc3d6de5a74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "659048492a0a43aab019da18cc0db4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1daec5231e9c4592b06f0a76592ea1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b6a8ebd7624825b20512aa048ef995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4e2f8dc2c49478e885a6a2afad0208a",
              "IPY_MODEL_6457beeaee2d4b6786f7eec2ad5fd64c",
              "IPY_MODEL_e4cba8d2f14940cda291cbfcf595b469"
            ],
            "layout": "IPY_MODEL_9d0e936cf87e48a18f9c60041a927add"
          }
        },
        "f4e2f8dc2c49478e885a6a2afad0208a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acc53ca9e83a4e57ab58ca26ae865c75",
            "placeholder": "​",
            "style": "IPY_MODEL_b32c20d607d5477fa6b4e96deecc1b7e",
            "value": "  ...adapter_model.safetensors: 100%"
          }
        },
        "6457beeaee2d4b6786f7eec2ad5fd64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b02ee66f38d41e8970acf63d826a473",
            "max": 528550256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97a59712f8784a67aa7d29dbe1c40393",
            "value": 528550256
          }
        },
        "e4cba8d2f14940cda291cbfcf595b469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8759e79213b4c4a874202810a4194f4",
            "placeholder": "​",
            "style": "IPY_MODEL_d5137b2f307b46b3bbb4c8b028b56791",
            "value": "  529MB /  529MB            "
          }
        },
        "9d0e936cf87e48a18f9c60041a927add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc53ca9e83a4e57ab58ca26ae865c75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32c20d607d5477fa6b4e96deecc1b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b02ee66f38d41e8970acf63d826a473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a59712f8784a67aa7d29dbe1c40393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8759e79213b4c4a874202810a4194f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5137b2f307b46b3bbb4c8b028b56791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rokugatsu/CloudAligner/blob/main/my_2025%E6%9C%80%E7%B5%82%E8%AA%B2%E9%A1%8C%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%B3%E3%83%B3%E3%83%98%E3%82%9A_%E6%A8%99%E6%BA%96%E3%82%B3%E3%83%BC%E3%83%88%E3%82%991%EF%BC%88SFT%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 0) 依存関係の固定（Colabの“環境ブレ”対策）\n",
        "# ============================================================\n",
        "# Colab（無料版）は、ある日突然プリインストール版が変わり、\n",
        "# それまで動いていた学習コードが壊れることが頻繁にあります。\n",
        "# そのため、このセルでは「一度全部消す → 互換が確認できたバージョンを入れ直す」\n",
        "# という“強制的な再現性確保”をしています。\n",
        "#\n",
        "# ※Errorが出力されることがありますが、「使用しないライブラリ」に関するエラーであれば、関係なく動作します。\n",
        "\n",
        "!pip -q uninstall -y numpy pandas datasets trl transformers accelerate peft unsloth unsloth-zoo bitsandbytes xformers\n",
        "!pip -q install \"numpy==2.0.2\" \"pandas==2.2.2\"\n",
        "!pip -q install \\\n",
        "  \"datasets==4.3.0\" \\\n",
        "  \"trl==0.24.0\" \\\n",
        "  \"transformers==4.56.2\" \\\n",
        "  \"accelerate==1.1.0\" \\\n",
        "  \"peft==0.13.2\" \\\n",
        "  \"bitsandbytes==0.45.0\"\n",
        "# unsloth / zoo を同系列で揃える（zoo側の要求に合わせる）\n",
        "# Unsloth本体と unsloth-zoo は“セット運用”が基本です。片方だけ上げると壊れがちです。\n",
        "!pip -q install \"unsloth-zoo==2025.12.7\" \"unsloth==2025.12.7\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a3eb81-c713-4bb6-ece2-42185f3fd6f6",
        "id": "Y6eTtMqkLzAl"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires datasets, which is not installed.\n",
            "sentence-transformers 5.2.2 requires transformers<6.0.0,>=4.41.0, which is not installed.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Cannot install accelerate==1.1.0 and trl==0.24.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 構造化データセットSFT（Unsloth / Colab T4）標準学習コード：実行ガイド\n",
        "\n",
        "本ノートブックは、**構造化出力を測るベンチマークスコア向上**を目的として、  \n",
        "小型LLM（Qwen3-4B Instruct-2507）に対して **SFT（Supervised Fine-Tuning）** を行う標準コードです。\n",
        "\n",
        "学習は **Unsloth + QLoRA（4bit）** を利用し、**Colab 無料版（T4）**で動作するようにメモリ最適化されています。\n"
      ],
      "metadata": {
        "id": "M6vtQKTcQ8Gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. このコードが行うこと（概要）\n"
      ],
      "metadata": {
        "id": "v0xXIVtoRnQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "このコードは大きく3段階で構成されています。\n",
        "\n",
        "1. **環境固定（依存パッケージのバージョン固定）**  \n",
        "   Colabの環境変化による不具合を避けるため、numpy/transformers/trl/unsloth等を特定バージョンで揃えます。\n",
        "\n",
        "2. **SFT（教師あり微調整）の実行**  \n",
        "   Hugging Face Hub 上の学習データセットを読み込み、ベースモデルに LoRA アダプタを差し込み、学習します。  \n",
        "   学習の損失（loss）は **assistant 出力部分だけ**にかかる設計です（structured output を学習させやすい）。\n",
        "\n",
        "3. **LoRAアダプタのHugging Faceへのアップロード**  \n",
        "   学習で得られた LoRA の重み（adapter）を HF Hub に保存できます。  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0bWkeEfIRZKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 2. 実行手順（最短手順）\n"
      ],
      "metadata": {
        "id": "56C03Zt2Rr3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 0: Colab の準備\n",
        "- ランタイムの種類を **GPU** に変更し、GPU が **T4** になっていることを確認してください。\n",
        "- 過去の実行で環境が壊れている場合は **Runtime > Factory reset** を推奨します。\n",
        "\n",
        "### Step 1: 依存関係インストール\n",
        "- 先頭の `pip uninstall` → `pip install` を上から順に実行します。\n",
        "- 実行後、バージョン表示が想定通りであることを確認します（`unsloth import OK` が出ること）。\n",
        "\n",
        "### Step 2: Hugging Face へログイン\n",
        "- `login()` を実行するとトークン入力が求められます。\n",
        "- 入力するトークンは、**WRITE権限**のものを使用してください。\n",
        "- ※学習データセットが公開ならログイン無しでも読める場合がありますが、標準手順としてログインします。\n",
        "\n",
        "### Step 3: 学習の実行\n",
        "- `main()` が呼ばれ、学習が開始します。\n",
        "- 学習中に `[LabelStats:train]` が表示されます。これは「loss対象トークンが極端にゼロになっていないか」の健康診断です。\n",
        "\n",
        "### Step 4: 学習成果物の確認、LoRAアダプタのhuggingfaceへのアップロード\n",
        "- 学習後、`OUT_LORA_DIR` に以下が保存されます（最低限）：\n",
        "  - `adapter_config.json`\n",
        "  - `adapter_model.safetensors`（または `adapter_model.bin`）\n",
        "  - tokenizer 関連ファイル\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fsijt4sARZM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 出力（何が生成されるか）\n",
        "\n"
      ],
      "metadata": {
        "id": "awaxrALwRxpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `OUT_LORA_DIR`（例：`/content/lora_structeval_t_qwen3_4b`）に、\n",
        "  **LoRAアダプタ（差分重み）**が保存されます。\n",
        "- このアダプタをベースモデルに適用して推論することで、StructEval-T のスコア改善を狙います。\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PLhfZsZpRZPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 4. 学習データセットの説明\n"
      ],
      "metadata": {
        "id": "fp2GXhJyQ1NZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4.1 データセット概要\n",
        "本コードで使用するデータセットは以下です：\n",
        "\n",
        "- HF Dataset: `u-10bei/structured_data_with_cot_dataset_512_v2`  \n",
        "  https://huggingface.co/datasets/u-10bei/structured_data_with_cot_dataset_512_v2\n",
        "\n",
        "このデータセットは、**構造化出力（CSV / JSON / XML / TOML / YAML）**を中心とした、\n",
        "形式変換・抽出タスク向けのSFTデータです。\n",
        "\n",
        "### 4.2 収録件数・split\n",
        "- Subset: `default`\n",
        "- Split: `train`\n",
        "- 行数：**約 3.65k rows**\n",
        "\n",
        "### 4.3 カラム（列）構造\n",
        "Viewer上で確認できる代表的なカラムは以下です。\n",
        "\n",
        "- `id`（文字列）\n",
        "- `category`（カテゴリ：複数値）\n",
        "- `subcategory`（サブカテゴリ：複数値）\n",
        "- `task`（タスク種別：複数値）\n",
        "- `seed`（生成や由来を示す識別子）\n",
        "- `messages`（**OpenAI messages形式のlist**）\n",
        "\n",
        "特に重要なのが `messages` で、各サンプルは以下のような形です：\n",
        "\n",
        "```json\n",
        "[\n",
        "  {\"role\": \"user\", \"content\": \"...指示と入力...\"},\n",
        "  {\"role\": \"assistant\", \"content\": \"...期待される出力...\"}\n",
        "]\n"
      ],
      "metadata": {
        "id": "tfLExuPZRZZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 実行コード"
      ],
      "metadata": {
        "id": "iesWWPf3RZdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1:依存関係インストール"
      ],
      "metadata": {
        "id": "m9UNQU8fPoGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 0) 依存関係の固定（Colabの“環境ブレ”対策）\n",
        "# ============================================================\n",
        "# Colab（無料版）は、ある日突然プリインストール版が変わり、\n",
        "# それまで動いていた学習コードが壊れることが頻繁にあります。\n",
        "# そのため、このセルでは「一度全部消す → 互換が確認できたバージョンを入れ直す」\n",
        "# という“強制的な再現性確保”をしています。\n",
        "#\n",
        "# ※Errorが出力されることがありますが、「使用しないライブラリ」に関するエラーであれば、関係なく動作します。\n",
        "\n",
        "!pip -q uninstall -y numpy pandas datasets trl transformers accelerate peft unsloth unsloth-zoo bitsandbytes xformers\n",
        "!pip -q install \"numpy==2.0.2\" \"pandas==2.2.2\"\n",
        "!pip -q install \\\n",
        "  \"datasets==4.3.0\" \\\n",
        "  \"trl==0.24.0\" \\\n",
        "  \"transformers==4.56.2\" \\\n",
        "  \"accelerate==1.1.0\" \\\n",
        "  \"peft==0.13.2\" \\\n",
        "  \"bitsandbytes==0.45.0\"\n",
        "# unsloth / zoo を同系列で揃える（zoo側の要求に合わせる）\n",
        "# Unsloth本体と unsloth-zoo は“セット運用”が基本です。片方だけ上げると壊れがちです。\n",
        "!pip -q install \"unsloth-zoo==2025.12.7\" \"unsloth==2025.12.7\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Bf7hi5wBSofx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aacad97-b8f7-40f3-9dea-da0a9a450386"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires datasets, which is not installed.\n",
            "sentence-transformers 5.2.2 requires transformers<6.0.0,>=4.41.0, which is not installed.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Cannot install accelerate==1.1.0 and trl==0.24.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ============================================================\n",
        "# 0.1) バージョン確認（“動くはず”の状態かを目視で確認）\n",
        "# ============================================================\n",
        "# ここで想定バージョンとズレている場合、\n",
        "# 後工程で原因不明のエラーが出る確率が一気に上がります。\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "import datasets, trl, transformers, torch\n",
        "\n",
        "print(\"numpy\", np.__version__)\n",
        "print(\"pandas\", pd.__version__)\n",
        "print(\"datasets\", datasets.__version__)\n",
        "print(\"trl\", trl.__version__)\n",
        "print(\"transformers\", transformers.__version__)\n",
        "print(\"torch\", torch.__version__)\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "print(\"unsloth import OK\")\n",
        "\n",
        "# 期待値：\n",
        "# numpy 2.0.2\n",
        "# pandas 2.2.2\n",
        "# datasets 4.3.0（または <4.4.0 で 4.0.* / 4.1.0 以外）\n",
        "# trl 0.24.0（または 0.18.2〜0.24.0 で 0.19.0以外）\n",
        "# unsloth import OK\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 0) Install (single cell)\n",
        "# -----------------------------\n",
        "# NOTE:\n",
        "# - Colabは初期状態が頻繁に変わるため、ピン留めで安定化します。\n",
        "#   もし依存関係が壊れている環境であれば、Runtime > Factory reset を推奨。\n",
        "\n",
        "# このセルを実行して、上の「期待値」にもしなっていない場合は、下記のコメントアウトを外して実行してみてください。\n",
        "# !pip -q install -U \\\n",
        "#   \"numpy==2.0.2\" \\\n",
        "#   \"pandas==2.2.2\" \\\n",
        "#   \"datasets==4.3.0\" \\\n",
        "#   \"trl==0.24.0\" \\\n",
        "#   \"transformers==4.57.3\" \\又は、4.56.2\n",
        "#   \"accelerate==1.1.0\" \\\n",
        "#   \"peft==0.13.2\" \\\n",
        "#   \"bitsandbytes==0.45.0\" \\\n",
        "#   \"unsloth-zoo==2025.12.7\" \\\n",
        "#   \"unsloth==2025.12.7\" \\\n",
        "#   \"huggingface_hub\"\n"
      ],
      "metadata": {
        "id": "JHkB4LAjS1Z2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb358e5-287a-4704-f5a8-cdb8f2946b59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy 2.0.2\n",
            "pandas 2.2.2\n",
            "datasets 4.3.0\n",
            "trl 0.24.0\n",
            "transformers 4.57.3\n",
            "torch 2.10.0+cu128\n",
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1458191610.py:17: UserWarning: WARNING: Unsloth should be imported before [trl, transformers] to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "unsloth import OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: HuggingFace ログイン\n",
        "\n",
        "Hugging Faceに自分のモデルやデータセットを保存したり、設定を変更したりするには、書き込み用の「トークン」が必要です。\n",
        "トークンは、以下の手順で取得できます。\n",
        "\n",
        "ステップ1：設定画面を開く\n",
        "- Hugging Face にログインします。(https://huggingface.co/)\n",
        "- 画面右上の自分のアイコンをクリックします。\n",
        "- メニューの中から 「Settings」（設定）を選択します。\n",
        "\n",
        "ステップ2：アクセストークンのページへ\n",
        "- 左側のサイドメニューにある 「Access Tokens」 をクリックします。\n",
        "\n",
        "ステップ3：新しいトークンを作成する\n",
        "- 画面中央にある 「+ Create new token」 ボタンをクリックします。\n",
        "- 設定ウィンドウが開くので、以下の2項目を入力・選択します。\n",
        "- Token Name: 自分が分かりやすい名前を付けます（例：my-upload-token など）。\n",
        "- Token type: ここが一番重要です！今回は、学習後のモデル（アダプタ）をアップロードするため、必ず 「Write」 を選択してください。\n",
        "- 下にある 「Create token」 ボタンを押して完了です。\n",
        "\n",
        "ステップ4：トークンをコピーして保存する\n",
        "- 作成されたトークンの横にある コピーアイコン（紙が重なったマーク） をクリックして、トークンをコピーします。\n",
        "\n",
        "- コピーした文字列は、メモ帳などに貼り付けて大切に保管してください。\n",
        "\n",
        "⚠️ 大切な注意点\n",
        "トークンは「パスワード」と同じです： このトークンが他人に知られると、あなたのリポジトリを勝手に書き換えられてしまう恐れがあります。GitHubなどにそのまま貼り付けて公開しないよう、十分注意してください。"
      ],
      "metadata": {
        "id": "mi78wnsDP6Yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# 1) HF login (once)\n",
        "# -----------------------------\n",
        "# Hugging Face（HF）はモデルやデータセットをホスティングするサービスです。\n",
        "# このコードでは「HF Hub上のデータセットを読む」「学習したLoRAをHFにアップする」ためにログインします。\n",
        "#\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import numpy as np, pandas as pd\n",
        "import datasets, trl, transformers, torch\n",
        "\n",
        "from huggingface_hub import login, HfApi\n",
        "login()  # Colab will prompt\n",
        "api = HfApi()"
      ],
      "metadata": {
        "id": "SrjUvUoPP6i9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "f4ef72adfe7144cea4026a7ee5ce5eb1",
            "e41827c8bcad44a4b590132cc3d93158",
            "babceeed66bb48149fcca7c3fd6ea94b",
            "ad6e7214efec4e6c9f5245a4781b7a69",
            "084eb9599045475990a5183796230970",
            "b3abce898fb840bca8e0420ff455dcd7",
            "fb4cf5dbac3a4556b931cde596a3ea1f",
            "7618cc47eaf84261921c7ef2b682d70a",
            "61036b8ddb0c4780bbb1665835d4d0bc",
            "b0a3e3503cc849a5af5eefa293a463b2",
            "30b2f3e22da845039f1d0970f12abaf6",
            "d57fb9b2be1144bf904f18bd49b48b89",
            "7c845d7ee87b4a9e8e5d4c15b49f5054",
            "660b373f49e84cf09c6e2b237a90d8c4",
            "7e57dee6bf9748038df40c2c0befc2f3",
            "3c8b0ac1decb452f9c58dedbfecabcd7",
            "d77e2ddcaab94b4ea4701a6cef58a228",
            "6cdc414dac904890bdb8965558bf1406",
            "1900604cee784b81a197b3be87f40805",
            "f8700cdd266b4501a4ab8c2e6276137b"
          ]
        },
        "outputId": "f060229e-e927-40f3-979d-61199b7bbc74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4ef72adfe7144cea4026a7ee5ce5eb1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3:学習の実行"
      ],
      "metadata": {
        "id": "3YyMQDqNRI2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 2) Training code\n",
        "# ============================================================\n",
        "# ここからがSFT本体です。\n",
        "# 大まかな流れ：\n",
        "#  1) 設定値（モデル名、データセット、LoRA設定、学習率など）を読み込む\n",
        "#  2) データセットをHFから取得し、必要な形（messages形式）を満たすものだけ残す\n",
        "#  3) tokenizerで「学習に使うテキスト」を作ってキャッシュする（高速化）\n",
        "#  4) ベースモデルを4bitでロードし、LoRAアダプタを差し込む\n",
        "#  5) Trainerで学習を回す\n",
        "#  6) LoRAアダプタを保存する\n"
      ],
      "metadata": {
        "id": "QXdP-QwRQg3G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ベースモデル：Qwen3-4B-Instruct-2507\n",
        "- GPU：T4（無料Colab）でも回るように、メモリ節約を強く意識しています。\n",
        "- 学習方式：QLoRA（4bitでベースを読み、LoRAアダプタのみ学習）\n",
        "  - “全部の重み”を学習するのではなく、LoRAアダプタ（軽量差分）だけを学習します。\n",
        "  - そのため、学習後に保存されるのも「アダプタ」中心になります。"
      ],
      "metadata": {
        "id": "QRNFLLFANPS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用可能なデータセット\n",
        "今回、運営において9種類の合成データセットを用意しました。\n",
        "\n",
        "- 1-1. https://huggingface.co/datasets/u-10bei/structured_data_with_cot_dataset_512_v2\n",
        "- 1-2. https://huggingface.co/datasets/u-10bei/structured_data_with_cot_dataset_512_v4\n",
        "- 1-3. https://huggingface.co/datasets/u-10bei/structured_data_with_cot_dataset_512_v5\n",
        "- 1-4.\n",
        "https://huggingface.co/datasets/u-10bei/structured_data_with_cot_dataset_512\n",
        "- 1-5.\n",
        "https://huggingface.co/datasets/u-10bei/structured_data_with_cot_dataset_v2\n",
        "- 1-6.\n",
        "https://huggingface.co/datasets/u-10bei/structured_data_with_cot_dataset\n",
        "- 2-1. https://huggingface.co/datasets/daichira/structured-3k-mix-sft\n",
        "- 2-2. https://huggingface.co/datasets/daichira/structured-5k-mix-sft\n",
        "- 2-3. https://huggingface.co/datasets/daichira/structured-hard-sft-4k\n",
        "\n",
        " この標準コードでは1-1を使用していますが、1-2以降を使用してもOKです。\n",
        " - 学習データセットを1-1以外に変更せずとも、後述の環境変数（4.ハイパーパラメータ）を変更することにより、モデル性能が向上する（修了要件を満たす）ことが可能です。\n",
        " - さらなる性能向上のため、これらのデータセットに追加で前処理を行ってから学習を行っても差し支えありません。\n",
        "\n",
        " 注意\n",
        "- このデータを使用するとスコアが上がることを保証するものではありません．\n",
        "- ご自身で組み合わせたり，カスタマイズして使用してみてください．\n",
        "- ただし，詳細資料に記載してあるルールは守ってください．\n"
      ],
      "metadata": {
        "id": "2ok0cPOcRbTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import shutil\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import TrainingArguments, Trainer, TrainerCallback\n"
      ],
      "metadata": {
        "id": "NK6nsyrSQdyF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 環境変数の設定\n",
        "# -----------------------------\n",
        "# 下記の値を書き換えることで、コード本体を編集せずに設定を変更できます。\n",
        "\n",
        "# 1. モデル・データセット関連\n",
        "os.environ[\"SFT_BASE_MODEL\"] = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "os.environ[\"SFT_DATASET_ID\"] = \"u-10bei/structured_data_with_cot_dataset_512_v2\"\n",
        "#os.environ[\"SFT_DATASET_ID\"] = \"daichira/structured-3k-mix-sft\"\n",
        "os.environ[\"SFT_OUT_LORA_DIR\"] = \"/content/lora_structeval_t_qwen3_4b\"\n",
        "\n",
        "# 2. 学習の基本パラメータ\n",
        "os.environ[\"SFT_SEED\"] = \"3407\"\n",
        "os.environ[\"SFT_VAL_RATIO\"] = \"0.05\"\n",
        "os.environ[\"SFT_MAX_SEQ_LEN\"] = \"512\"\n",
        "\n",
        "# 3. LoRA (アダプタ) 設定\n",
        "os.environ[\"SFT_LORA_R\"] = \"64\"\n",
        "os.environ[\"SFT_LORA_ALPHA\"] = \"128\"\n",
        "os.environ[\"SFT_LORA_DROPOUT\"] = \"0\"\n",
        "os.environ[\"SFT_LORA_TARGET_MODULES\"] = \"q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj\"\n",
        "\n",
        "# 4. ハイパーパラメータ\n",
        "os.environ[\"SFT_EPOCHS\"] = \"1\"\n",
        "os.environ[\"SFT_PER_DEVICE_TRAIN_BS\"] = \"2\"\n",
        "os.environ[\"SFT_PER_DEVICE_EVAL_BS\"] = \"2\"\n",
        "os.environ[\"SFT_GRAD_ACCUM\"] = \"8\"\n",
        "#os.environ[\"SFT_LR\"] = \"1e-6\" #Default\n",
        "os.environ[\"SFT_LR\"] = \"1e-4\"\n",
        "os.environ[\"SFT_WARMUP_RATIO\"] = \"0.1\"\n",
        "os.environ[\"SFT_WEIGHT_DECAY\"] = \"0.05\"\n",
        "\n",
        "# 5. ステップ・保存設定\n",
        "os.environ[\"SFT_MAX_STEPS\"] = \"-1\" # -1でエポックベース。動作確認時は 10 などに。\n",
        "os.environ[\"SFT_LOGGING_STEPS\"] = \"10\"\n",
        "os.environ[\"SFT_EVAL_STEPS\"] = \"50\"\n",
        "os.environ[\"SFT_SAVE_STEPS\"] = \"100\"\n",
        "os.environ[\"SFT_SAVE_TOTAL_LIMIT\"] = \"2\"\n",
        "\n",
        "# 6. 特殊学習設定 (CoTマスク・アップサンプリング)\n",
        "os.environ[\"SFT_MASK_COT\"] = \"1\" # \"1\" で有効, \"0\" で無効\n",
        "os.environ[\"SFT_OUTPUT_MARKERS\"] = \"Output:,OUTPUT:,Final:,Answer:,Result:,Response:\"\n",
        "os.environ[\"SFT_OUTPUT_LEARN_MODE\"] = \"after_marker\" # \"after_marker\" または \"from_marker\"\n",
        "os.environ[\"SFT_USE_UPSAMPLING\"] = \"0\" # \"1\" で有効, \"0\" で無効  # データ2-1,2-2,2-3 専用\n",
        "os.environ[\"SFT_UPSAMPLE_RULES\"] = '{\"xml_to_yaml\": 2.0,\"xml_to_toml\": 2.0}' # 例: '{\"json_to_xml\": 1.8, \"text_to_yaml\": 1.6}' # データ2-1,2-2,2-3 専用\n",
        "\n",
        "print(\"環境変数の設定が完了しました。\")"
      ],
      "metadata": {
        "id": "z7t5SanBUJJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f7012b-8cb4-4eda-e988-6f52bcee9922"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "環境変数の設定が完了しました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jOf9hrSaNl9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20536c83-65a8-40af-c6c9-8538129c7609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loading dataset from HF Hub: u-10bei/structured_data_with_cot_dataset_512_v2\n",
            "[INFO] Loading base model: Qwen/Qwen3-4B-Instruct-2507\n",
            "==((====))==  Unsloth 2025.12.7: Fast Qwen3 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.34. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.12.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Checking all-masked samples before filtering...\n",
            "[CHECK] all-masked samples in 197: 9 (4.6%)\n",
            "[INFO] Filtering train/val to remove all-masked samples...\n",
            "[INFO] New sizes: train = 3547 val = 187\n",
            "[INFO] Checking all-masked samples after filtering...\n",
            "[CHECK] all-masked samples in 187: 0 (0.0%)\n",
            "[INFO] Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4122007349.py:509: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer._unsloth___init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 3,547 | Num Epochs = 1 | Total steps = 222\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 132,120,576 of 4,154,588,672 (3.18% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [222/222 16:39, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.754900</td>\n",
              "      <td>0.874180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.777600</td>\n",
              "      <td>0.810126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.794500</td>\n",
              "      <td>0.788243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.738600</td>\n",
              "      <td>0.779297</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LabelStats:train] step=10 valid_ratio=0.4548\n",
            "\n",
            "[LabelStats:train] step=20 valid_ratio=0.4786\n",
            "\n",
            "[LabelStats:train] step=30 valid_ratio=0.4888\n",
            "\n",
            "[LabelStats:train] step=40 valid_ratio=0.5755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Not an error, but Qwen3ForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LabelStats:train] step=50 valid_ratio=0.4728\n",
            "\n",
            "[LabelStats:train] step=60 valid_ratio=0.6064\n",
            "\n",
            "[LabelStats:train] step=70 valid_ratio=0.5915\n",
            "\n",
            "[LabelStats:train] step=80 valid_ratio=0.5277\n",
            "\n",
            "[LabelStats:train] step=90 valid_ratio=0.5774\n",
            "\n",
            "[LabelStats:train] step=100 valid_ratio=0.4613\n",
            "\n",
            "[LabelStats:train] step=110 valid_ratio=0.5955\n",
            "\n",
            "[LabelStats:train] step=120 valid_ratio=0.5868\n",
            "\n",
            "[LabelStats:train] step=130 valid_ratio=0.6039\n",
            "\n",
            "[LabelStats:train] step=140 valid_ratio=0.5573\n",
            "\n",
            "[LabelStats:train] step=150 valid_ratio=0.4853\n",
            "\n",
            "[LabelStats:train] step=160 valid_ratio=0.4579\n",
            "\n",
            "[LabelStats:train] step=170 valid_ratio=0.4608\n",
            "\n",
            "[LabelStats:train] step=180 valid_ratio=0.5417\n",
            "\n",
            "[LabelStats:train] step=190 valid_ratio=0.4738\n",
            "\n",
            "[LabelStats:train] step=200 valid_ratio=0.5225\n",
            "\n",
            "[LabelStats:train] step=210 valid_ratio=0.6295\n",
            "\n",
            "[LabelStats:train] step=220 valid_ratio=0.5681\n",
            "[INFO] Saving adapter & tokenizer...\n",
            "[INFO] Done. Saved to /content/lora_structeval_t_qwen3_4b\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# 2.1) Config (env-overridable)\n",
        "# -----------------------------\n",
        "# “環境変数で上書きできる設定”を用意しています。\n",
        "# つまり、コードを編集しなくても、Colabの環境変数を変えるだけで\n",
        "# ベースモデル名、学習率、エポック数などを変更できる設計です。\n",
        "#\n",
        "# この設計のメリット：\n",
        "# - “標準コード”は同じまま、ハイパーパラメータだけ試せる（再現性が高い）\n",
        "\n",
        "def _getenv(name: str, default: str):\n",
        "    return os.environ.get(name, default)\n",
        "\n",
        "def _getenv_int(name: str, default: int) -> int:\n",
        "    try:\n",
        "        return int(os.environ.get(name, str(default)))\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "def _getenv_float(name: str, default: float) -> float:\n",
        "    try:\n",
        "        return float(os.environ.get(name, str(default)))\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "# 学習の“出発点”となるベースモデル（4B）\n",
        "BASE_MODEL_ID = _getenv(\"SFT_BASE_MODEL\", \"Qwen/Qwen3-4B-Instruct-2507\")\n",
        "\n",
        "# 学習に使うSFTデータセット（HF Hub上に置かれている想定）\n",
        "DATASET_ID    = _getenv(\"SFT_DATASET_ID\", \"u-10bei/structured_data_with_cot_dataset_512_v2\")\n",
        "\n",
        "# 学習後に保存されるLoRAアダプタの出力先（ローカル）\n",
        "OUT_LORA_DIR  = _getenv(\"SFT_OUT_LORA_DIR\", \"/content/lora_structeval_t_qwen3_4b\") # HFアップロードするアダプタ名と合わせる\n",
        "\n",
        "SEED        = _getenv_int(\"SFT_SEED\", 3407)\n",
        "VAL_RATIO   = _getenv_float(\"SFT_VAL_RATIO\", 0.05)\n",
        "\n",
        "# 1サンプルあたり最大何トークンまで見るか（長いほど情報を見られるが、GPUメモリと時間が増える）\n",
        "MAX_SEQ_LEN = _getenv_int(\"SFT_MAX_SEQ_LEN\", 512)\n",
        "\n",
        "# LoRA Config（＝“どれくらいの表現力を持つ差分を学習するか”）\n",
        "LORA_R       = _getenv_int(\"SFT_LORA_R\", 64)\n",
        "LORA_ALPHA   = _getenv_int(\"SFT_LORA_ALPHA\", 128)\n",
        "LORA_DROPOUT = _getenv_float(\"SFT_LORA_DROPOUT\", 0)\n",
        "LORA_TARGET_MODULES = (\n",
        "    _getenv(\"SFT_LORA_TARGET_MODULES\", \"q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj\").split(\",\")\n",
        ")\n",
        "\n",
        "# Train hyperparams（学習の基本設定）\n",
        "NUM_TRAIN_EPOCHS            = _getenv_int(\"SFT_EPOCHS\", 1)\n",
        "PER_DEVICE_TRAIN_BATCH_SIZE = _getenv_int(\"SFT_PER_DEVICE_TRAIN_BS\", 2)\n",
        "PER_DEVICE_EVAL_BATCH_SIZE  = _getenv_int(\"SFT_PER_DEVICE_EVAL_BS\", 2)\n",
        "\n",
        "# 勾配累積：GPUに一度に載せられるバッチが小さい時に、複数ステップ分を貯めて“大きいバッチ相当”にする\n",
        "GRAD_ACCUM                  = _getenv_int(\"SFT_GRAD_ACCUM\", 8)\n",
        "\n",
        "LR                          = _getenv_float(\"SFT_LR\", 1e-6)\n",
        "WARMUP_RATIO                = _getenv_float(\"SFT_WARMUP_RATIO\", 0.1)\n",
        "\n",
        "# Debug / quick check\n",
        "# MAX_STEPSを小さくすると“動作確認だけ”の短時間学習ができます（本番は -1 のまま）\n",
        "MAX_STEPS        = _getenv_int(\"SFT_MAX_STEPS\", -1)\n",
        "LOGGING_STEPS    = _getenv_int(\"SFT_LOGGING_STEPS\", 10)\n",
        "EVAL_STEPS       = _getenv_int(\"SFT_EVAL_STEPS\", 50)\n",
        "SAVE_STEPS       = _getenv_int(\"SFT_SAVE_STEPS\", 100)\n",
        "SAVE_TOTAL_LIMIT = _getenv_int(\"SFT_SAVE_TOTAL_LIMIT\", 2)\n",
        "WEIGHT_DECAY     = _getenv_float(\"SFT_WEIGHT_DECAY\", 0.05)\n",
        "\n",
        "# Optional: upsampling rules\n",
        "# 特定のサブカテゴリ（例：難しいタスク）を“多めに学習させる”ための仕組み。\n",
        "# 標準ではOFFになっています。\n",
        "UPSAMPLE_ENABLE     = _getenv(\"SFT_USE_UPSAMPLING\", \"0\") in (\"1\",\"true\",\"True\")\n",
        "UPSAMPLE_RULES_JSON = _getenv(\"SFT_UPSAMPLE_RULES\", \"\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2.2) Seed & Utils\n",
        "# -----------------------------\n",
        "# 乱数（シャッフルやサンプリング）を固定して、再現性を担保します。\n",
        "# seedが同じなら、原則として同じ分割・同じ抽出になりやすいです。\n",
        "\n",
        "def seed_everything(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(SEED)\n",
        "\n",
        "def ensure_openai_messages(ds: Dataset, msg_col: str = \"messages\") -> None:\n",
        "    # データが「messages: [{role, content}, ...]」形式かをチェックします。\n",
        "    # これは ChatGPT形式（OpenAIのChat Completions形式に似た）で、\n",
        "    # tokenizer.apply_chat_template で安全に文字列化するために必要です。\n",
        "    row0 = ds[0]\n",
        "    ex = row0.get(msg_col, None)\n",
        "    if not isinstance(ex, list):\n",
        "        raise ValueError(f\"Dataset must have list-style 'messages'. Got {type(ex)}\")\n",
        "\n",
        "def has_any_nonempty_assistant_turn(msgs: List[Dict[str, Any]]) -> bool:\n",
        "    # “assistantの発話が空じゃない”ものが1回でも含まれるか？\n",
        "    # SFTでは「正解例（assistantの出力）」がないと学習できないため。\n",
        "    return any(m.get(\"role\") == \"assistant\" and str(m.get(\"content\", \"\")).strip() != \"\" for m in msgs)\n",
        "\n",
        "def ends_with_nonempty_assistant(ex: Dict[str, Any]) -> bool:\n",
        "    # 最後のターンが assistant の回答になっているサンプルだけを使います。\n",
        "    # こうしておくと「最後のassistantだけ学習する（assistant-only loss）」設計と相性が良いです。\n",
        "    msgs = ex.get(\"messages\", [])\n",
        "    if not msgs or msgs[-1].get(\"role\") != \"assistant\":\n",
        "        return False\n",
        "    c = msgs[-1].get(\"content\", \"\")\n",
        "    return isinstance(c, str) and c.strip() != \"\"\n",
        "\n",
        "def shuffle_split(ds: Dataset, val_ratio: float, seed: int) -> Tuple[Dataset, Dataset]:\n",
        "    # データをシャッフルして train/val に分割します。\n",
        "    # val（検証）を持つことで「学習が進むほど性能が上がっているか／過学習していないか」を見られます。\n",
        "    ds_shuf = ds.shuffle(seed=seed)\n",
        "    n = len(ds_shuf)\n",
        "    n_val = max(1, int(round(n * val_ratio)))\n",
        "    return ds_shuf.select(range(n_val, n)), ds_shuf.select(range(n_val))\n",
        "\n",
        "def make_text_cache_builder(tokenizer):\n",
        "    # messages形式 → 実際にモデルに入力する“1本のテキスト”へ変換する関数を作ります。さらに「トークン長（truncationなし）」もキャッシュします。\n",
        "    #\n",
        "    # full_text  : ユーザー＋アシスタント（正解）まで含んだ全文\n",
        "    # prefix_text: “最後のassistantの直前まで”の文（＝ここからassistantを生成させたい）\n",
        "    #\n",
        "    # この2つを持つことで、後のcollatorで「assistant部分だけをloss対象にする境界」を計算できます。\n",
        "\n",
        "    def _build(batch):\n",
        "        full_out = []\n",
        "        prefix_out = []\n",
        "        full_len_out = []\n",
        "        prefix_len_out = []\n",
        "\n",
        "        for msgs in batch[\"messages\"]:\n",
        "            full = tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=False)\n",
        "            prefix = tokenizer.apply_chat_template(msgs[:-1], tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "            full_out.append(full)\n",
        "            prefix_out.append(prefix)\n",
        "\n",
        "            # 重要：ここで truncation=False で token 長だけ計算してキャッシュする\n",
        "            # add_special_tokens=False はあなたの現行設計に合わせる（テンプレ側で必要トークンが入る想定）\n",
        "            full_ids = tokenizer(full, add_special_tokens=False, truncation=False)[\"input_ids\"]\n",
        "            prefix_ids = tokenizer(prefix, add_special_tokens=False, truncation=False)[\"input_ids\"]\n",
        "\n",
        "            full_len_out.append(len(full_ids))\n",
        "            prefix_len_out.append(len(prefix_ids))\n",
        "\n",
        "        return {\n",
        "            \"full_text\": full_out,\n",
        "            \"prefix_text\": prefix_out,\n",
        "            \"full_input_ids_len\": full_len_out,\n",
        "            \"prefix_input_ids_len\": prefix_len_out,\n",
        "        }\n",
        "\n",
        "    return _build\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2.3) Collator (assistant-only loss)\n",
        "# -----------------------------\n",
        "# collatorは「生のサンプル群 → 学習に必要なテンソル(input_ids/labels等)」に変換する部品です。\n",
        "#\n",
        "# ここがこの学習コードの“設計思想”の核心：\n",
        "# - 入力（user/system）も含めてモデルには読ませる\n",
        "# - ただし loss（誤差）を計算するのは assistant の出力部分だけ\n",
        "#\n",
        "# これにより：\n",
        "# - 「プロンプトを丸暗記させる」方向に学習が引っ張られにくい\n",
        "# - “回答の形式”や“出力の正確さ”に学習の力点を置きます。\n",
        "\n",
        "# 使用データセットによる仕様の違い\n",
        "# データセット1：Output: が 100% なので CoT マスクが常に動き、Output本体だけ学習\n",
        "# データセット2：Output: 系ラベルが存在しないため、CoTマスクは発動せず、“出力本体”を学習\n",
        "\n",
        "# --- CoT mask settings (env overridable) ---\n",
        "MASK_COT = _getenv(\"SFT_MASK_COT\", \"1\") in (\"1\",\"true\",\"True\")\n",
        "OUTPUT_MARKERS = [s.strip() for s in _getenv(\n",
        "    \"SFT_OUTPUT_MARKERS\",\n",
        "    \"Output:,OUTPUT:,Final:,Answer:,Result:,Response:\"\n",
        ").split(\",\") if s.strip()]\n",
        "OUTPUT_LEARN_MODE = _getenv(\"SFT_OUTPUT_LEARN_MODE\", \"after_marker\")  # after_marker / from_marker\n",
        "\n",
        "@dataclass\n",
        "class AssistantOnlyCollatorCached:\n",
        "    tokenizer: Any\n",
        "    max_length: int = MAX_SEQ_LEN\n",
        "\n",
        "    def _find_subsequence(self, seq: List[int], sub: List[int]) -> int:\n",
        "        if not sub or len(sub) > len(seq):\n",
        "            return -1\n",
        "        for i in range(0, len(seq) - len(sub) + 1):\n",
        "            if seq[i:i+len(sub)] == sub:\n",
        "                return i\n",
        "        return -1\n",
        "\n",
        "    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
        "        tok = self.tokenizer\n",
        "        full_texts   = [ex[\"full_text\"] for ex in batch]\n",
        "        prefix_texts = [ex[\"prefix_text\"] for ex in batch]\n",
        "\n",
        "        old_trunc = getattr(tok, \"truncation_side\", \"right\")\n",
        "        old_pad   = getattr(tok, \"padding_side\", \"right\")\n",
        "        tok.truncation_side = \"left\"\n",
        "        tok.padding_side    = \"right\"\n",
        "\n",
        "        try:\n",
        "            full_enc_tr = tok(\n",
        "                full_texts,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=self.max_length,\n",
        "                add_special_tokens=False,\n",
        "            )\n",
        "            input_ids = full_enc_tr[\"input_ids\"]\n",
        "            attention_mask = full_enc_tr[\"attention_mask\"]\n",
        "            labels = torch.full_like(input_ids, fill_value=-100)\n",
        "\n",
        "            full_ids_nt   = tok(full_texts,   return_tensors=None, padding=False, truncation=False, add_special_tokens=False)[\"input_ids\"]\n",
        "            prefix_ids_nt = tok(prefix_texts, return_tensors=None, padding=False, truncation=False, add_special_tokens=False)[\"input_ids\"]\n",
        "\n",
        "            marker_token_seqs = []\n",
        "            if MASK_COT and OUTPUT_MARKERS:\n",
        "                for m in OUTPUT_MARKERS:\n",
        "                    mid = tok(m, add_special_tokens=False, truncation=False)[\"input_ids\"]\n",
        "                    if not mid:\n",
        "                        continue\n",
        "                    mid_nl = tok(m + \"\\n\", add_special_tokens=False, truncation=False)[\"input_ids\"]\n",
        "                    mid_crlf = tok(m + \"\\r\\n\", add_special_tokens=False, truncation=False)[\"input_ids\"]\n",
        "                    marker_token_seqs.append((mid, mid_nl, mid_crlf))\n",
        "\n",
        "            for i in range(input_ids.size(0)):\n",
        "                trunc_left = max(0, len(full_ids_nt[i]) - self.max_length)\n",
        "                boundary = len(prefix_ids_nt[i]) - trunc_left\n",
        "                full_len_tr = int(attention_mask[i].sum().item())\n",
        "\n",
        "                # assistant開始が見えていない => 学習対象外（元コード方針を維持）\n",
        "                if boundary <= 0 or boundary >= full_len_tr:\n",
        "                    continue\n",
        "\n",
        "                span_start = boundary\n",
        "                span_end   = full_len_tr\n",
        "\n",
        "                # デフォルト：assistant全体を学習（データセット2はここに落ちる）\n",
        "                learn_start = span_start\n",
        "\n",
        "                # CoTマスク：Output marker が見つかったときだけ学習開始点を進める（データセット1で発動）\n",
        "                if MASK_COT and marker_token_seqs:\n",
        "                    visible_ids = input_ids[i, :full_len_tr].tolist()\n",
        "                    assistant_ids = visible_ids[span_start:span_end]\n",
        "\n",
        "                    best_out = None  # (out_pos, after_pos)\n",
        "                    for mid, mid_nl, mid_crlf in marker_token_seqs:\n",
        "                        # 改行付き優先\n",
        "                        p = self._find_subsequence(assistant_ids, mid_nl)\n",
        "                        if p != -1:\n",
        "                            out_pos = span_start + p\n",
        "                            after_pos = out_pos + len(mid_nl)\n",
        "                        else:\n",
        "                            p = self._find_subsequence(assistant_ids, mid_crlf)\n",
        "                            if p != -1:\n",
        "                                out_pos = span_start + p\n",
        "                                after_pos = out_pos + len(mid_crlf)\n",
        "                            else:\n",
        "                                p = self._find_subsequence(assistant_ids, mid)\n",
        "                                if p == -1:\n",
        "                                    continue\n",
        "                                out_pos = span_start + p\n",
        "                                after_pos = out_pos + len(mid)\n",
        "\n",
        "                        if (best_out is None) or (out_pos < best_out[0]):\n",
        "                            best_out = (out_pos, after_pos)\n",
        "\n",
        "                    if best_out is not None:\n",
        "                        out_pos, after_pos = best_out\n",
        "                        if OUTPUT_LEARN_MODE == \"from_marker\":\n",
        "                            learn_start = out_pos\n",
        "                        else:\n",
        "                            learn_start = after_pos\n",
        "                        learn_start = max(span_start, min(learn_start, span_end))\n",
        "\n",
        "                if learn_start < span_end:\n",
        "                    labels[i, learn_start:span_end] = input_ids[i, learn_start:span_end]\n",
        "\n",
        "            labels[attention_mask == 0] = -100\n",
        "            return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
        "        finally:\n",
        "            tok.truncation_side = old_trunc\n",
        "            tok.padding_side    = old_pad\n",
        "\n",
        "import random, torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def filter_has_supervision(ds, collator):\n",
        "    keep = []\n",
        "    for i in range(len(ds)):\n",
        "        out = collator([ds[i]])\n",
        "        if (out[\"labels\"][0] != -100).sum().item() > 0:\n",
        "            keep.append(i)\n",
        "    return ds.select(keep)\n",
        "\n",
        "\n",
        "def count_all_masked(ds, collator, n=200, seed=3407):\n",
        "    rng = random.Random(seed)\n",
        "    n = min(n, len(ds))\n",
        "    idxs = [rng.randrange(0, len(ds)) for _ in range(n)]\n",
        "    all_masked = 0\n",
        "    for i in idxs:\n",
        "        out = collator([ds[i]])\n",
        "        labels = out[\"labels\"][0]\n",
        "        if (labels != -100).sum().item() == 0:\n",
        "            all_masked += 1\n",
        "    print(f\"[CHECK] all-masked samples in {n}: {all_masked} ({all_masked/max(1,n):.1%})\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2.4) Optional upsampling\n",
        "# -----------------------------\n",
        "# upsamplingは「特定の種類のデータを多めに学習させる」テクニックです。\n",
        "# 例：\n",
        "# - JSONは得意だがYAMLは苦手 → YAML関連サンプルを2倍にする\n",
        "# - 特定のsubcategoryが点数に効く → そこを厚くする\n",
        "# ただし、やりすぎると他が弱くなることもあります（トレードオフ）。\n",
        "# 学習データセットの品質が悪い等の原因で、却って性能が低下することもあります。\n",
        "# その場合、学習データセットを観察し、追加の前処理が有効であることも多いです。\n",
        "\n",
        "def apply_upsampling(train_ds: Dataset) -> Dataset:\n",
        "    if not UPSAMPLE_ENABLE or not UPSAMPLE_RULES_JSON:\n",
        "        return train_ds\n",
        "    try:\n",
        "        rules = json.loads(UPSAMPLE_RULES_JSON)\n",
        "        if not isinstance(rules, dict) or not rules:\n",
        "            return train_ds\n",
        "    except Exception:\n",
        "        return train_ds\n",
        "\n",
        "    packs = train_ds[\"subcategory\"] if \"subcategory\" in train_ds.column_names else [None]*len(train_ds)\n",
        "    pack_field = train_ds[\"pack\"] if \"pack\" in train_ds.column_names else [None]*len(train_ds)\n",
        "\n",
        "    w = []\n",
        "    for sub, pk in zip(packs, pack_field):\n",
        "        weight = 1.0\n",
        "        ssub = str(sub or \"\")\n",
        "        spk  = str(pk or \"\")\n",
        "        for pat, mult in rules.items():\n",
        "            try:\n",
        "                m = float(mult)\n",
        "            except Exception:\n",
        "                m = 1.0\n",
        "            if pat.startswith(\"pack:\"):\n",
        "                if spk == pat.split(\":\",1)[1]:\n",
        "                    weight *= max(0.0, m)\n",
        "            else:\n",
        "                if pat in ssub:\n",
        "                    weight *= max(0.0, m)\n",
        "        w.append(weight)\n",
        "\n",
        "    w = np.asarray(w, dtype=np.float64)\n",
        "    if (w <= 0).all() or w.sum() == 0:\n",
        "        return train_ds\n",
        "\n",
        "    p = w / w.sum()\n",
        "    n = len(train_ds)\n",
        "    idx = np.random.choice(np.arange(n), size=n, replace=True, p=p)\n",
        "    print(\"[UPSAMPLE] rules:\", rules)\n",
        "    return train_ds.select(idx.tolist())\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2.5) Callback (monitor)\n",
        "# -----------------------------\n",
        "# 学習中のデバッグ用コールバックです。\n",
        "# ここでは「labelsのうち、実際にloss対象になっているトークン割合」を時々表示します。\n",
        "#\n",
        "# 意味：\n",
        "# - valid_ratio が極端に小さい → “学習していない”のと同じ（ラベルがほぼ -100）\n",
        "# - valid_ratio が適度にある → assistant部分にしっかりlossが乗っている\n",
        "#\n",
        "# 初学者向けに言うと：\n",
        "# - これは“学習がちゃんと効いているかの健康診断”です。\n",
        "\n",
        "class LabelStatsCallback(TrainerCallback):\n",
        "    def __init__(self, dataset, collator, name=\"train\", every_n_steps=100):\n",
        "        self.dataset, self.collator, self.name, self.every_n_steps = dataset, collator, name, every_n_steps\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        if (state.global_step % self.every_n_steps) == 0:\n",
        "            batch = [self.dataset[random.randint(0, len(self.dataset)-1)] for _ in range(8)]\n",
        "            out = self.collator(batch)\n",
        "            valid = (out[\"labels\"] != -100).sum().item()\n",
        "            total = (out[\"attention_mask\"] == 1).sum().item()\n",
        "            print(f\"\\n[LabelStats:{self.name}] step={state.global_step} valid_ratio={valid/max(1,total):.4f}\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2.6) Main\n",
        "# -----------------------------\n",
        "# 学習を実行します。\n",
        "\n",
        "def main():\n",
        "    os.makedirs(OUT_LORA_DIR, exist_ok=True)\n",
        "\n",
        "    # if you used /content/your_id cache dirs etc, remove to avoid confusion\n",
        "    if os.path.exists(\"/content/your_id\"):\n",
        "        shutil.rmtree(\"/content/your_id\")\n",
        "\n",
        "    print(f\"[INFO] Loading dataset from HF Hub: {DATASET_ID}\")\n",
        "    ds_all = load_dataset(DATASET_ID, split=\"train\")\n",
        "\n",
        "    # データ形式チェック（messagesがlistであること）\n",
        "    ensure_openai_messages(ds_all)\n",
        "\n",
        "    # 学習できるサンプルだけ残す（assistantが空なら教師信号が無い）\n",
        "    ds_all = ds_all.filter(lambda ex: has_any_nonempty_assistant_turn(ex[\"messages\"])) # そのほかの要素も追加する\n",
        "    ds_all = ds_all.filter(ends_with_nonempty_assistant)\n",
        "\n",
        "    # train/val分割\n",
        "    train_ds, val_ds = shuffle_split(ds_all, VAL_RATIO, SEED)\n",
        "\n",
        "    # Optional: upsampling by rule（分割後に適用）\n",
        "    train_ds = apply_upsampling(train_ds)\n",
        "\n",
        "    print(\"[INFO] Loading base model:\", BASE_MODEL_ID)\n",
        "\n",
        "    # Unslothでベースモデルを読み込む（4bitロードで省メモリ）\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=BASE_MODEL_ID,\n",
        "        max_seq_length=MAX_SEQ_LEN,\n",
        "        dtype=None,\n",
        "        load_in_4bit=True,\n",
        "    )\n",
        "\n",
        "    # Cache chat template renders（tokenizerが必要なのでここで初めてbuild_cacheを作る）\n",
        "    build_cache = make_text_cache_builder(tokenizer)\n",
        "\n",
        "    train_ds = train_ds.map(build_cache, batched=True, num_proc=1, desc=\"Caching train\")\n",
        "    val_ds   = val_ds.map(build_cache,   batched=True, num_proc=1, desc=\"Caching val\")\n",
        "\n",
        "    # Attach LoRA\n",
        "    # ここで「学習される部分（LoRAアダプタ）」をモデルに追加します。\n",
        "    # 学習対象は LoRA のパラメータだけになり、ベースモデルの巨大な重みは固定されます。\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        r=LORA_R,\n",
        "        target_modules=LORA_TARGET_MODULES,\n",
        "        lora_alpha=LORA_ALPHA,\n",
        "        lora_dropout=LORA_DROPOUT,\n",
        "        use_gradient_checkpointing=\"unsloth\",\n",
        "        random_state=SEED,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Transformersの引数名がバージョンで揺れることがあります。\n",
        "    # 今回のバージョンでは eval_strategy を使います。\n",
        "    args = TrainingArguments(\n",
        "        output_dir=OUT_LORA_DIR,\n",
        "        num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "        per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
        "        per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRAD_ACCUM,\n",
        "        learning_rate=LR,\n",
        "        warmup_ratio=WARMUP_RATIO,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "\n",
        "        logging_steps=LOGGING_STEPS,\n",
        "\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=EVAL_STEPS,\n",
        "\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=SAVE_STEPS,\n",
        "        save_total_limit=SAVE_TOTAL_LIMIT,\n",
        "\n",
        "        max_steps=MAX_STEPS,  # -1 => epoch-based\n",
        "\n",
        "        bf16=True, # T4の場合は False, A100の場合は True が推奨\n",
        "        fp16=False,            # T4向け（T4はbf16が弱いのでfp16を使うのが一般的）\n",
        "\n",
        "        push_to_hub=False,\n",
        "        report_to=\"none\",\n",
        "\n",
        "        group_by_length=False,\n",
        "        remove_unused_columns=False,\n",
        "    )\n",
        "\n",
        "    # assistant-only loss の collator を使う\n",
        "    collator = AssistantOnlyCollatorCached(tokenizer=tokenizer, max_length=MAX_SEQ_LEN)\n",
        "\n",
        "    # --- NaN対策：all-masked（教師トークン0）を除去して評価を安定化 ---\n",
        "    print(\"[INFO] Checking all-masked samples before filtering...\")\n",
        "    count_all_masked(val_ds, collator, n=len(val_ds), seed=SEED)\n",
        "\n",
        "    print(\"[INFO] Filtering train/val to remove all-masked samples...\")\n",
        "    train_ds = filter_has_supervision(train_ds, collator)\n",
        "    val_ds   = filter_has_supervision(val_ds, collator)\n",
        "\n",
        "    print(\"[INFO] New sizes:\", \"train =\", len(train_ds), \"val =\", len(val_ds))\n",
        "    print(\"[INFO] Checking all-masked samples after filtering...\")\n",
        "    count_all_masked(val_ds, collator, n=len(val_ds), seed=SEED)\n",
        "\n",
        "\n",
        "    # Trainer（Transformersの標準学習ループ）\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        data_collator=collator,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    # 監視用コールバックを追加（学習が効いているかのヘルスチェック）\n",
        "    trainer.add_callback(LabelStatsCallback(train_ds, collator, name=\"train\", every_n_steps=LOGGING_STEPS))\n",
        "\n",
        "    print(\"[INFO] Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # 学習後の保存：LoRAアダプタ＆tokenizer\n",
        "    print(\"[INFO] Saving adapter & tokenizer...\")\n",
        "    model.save_pretrained(OUT_LORA_DIR)\n",
        "    tokenizer.save_pretrained(OUT_LORA_DIR)\n",
        "    print(f\"[INFO] Done. Saved to {OUT_LORA_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "577d1b65"
      },
      "source": [
        "アップサンプリングを有効にして、ルールを設定するには、`z7t5SanBUJJu` セル内の環境変数設定を以下のように変更してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53ece235"
      },
      "source": [
        "# -----------------------------\n",
        "# 環境変数の設定\n",
        "# -----------------------------\n",
        "# 下記の値を書き換えることで、コード本体を編集せずに設定を変更できます。\n",
        "\n",
        "# 1. モデル・データセット関連\n",
        "os.environ[\"SFT_BASE_MODEL\"] = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "#os.environ[\"SFT_DATASET_ID\"] = \"u-10bei/structured_data_with_cot_dataset_512_v2\"\n",
        "os.environ[\"SFT_DATASET_ID\"] = \"u-10bei/structured_data_with_cot_dataset_512_v4\"\n",
        "os.environ[\"SFT_OUT_LORA_DIR\"] = \"/content/lora_structeval_t_qwen3_4b\"\n",
        "\n",
        "# 2. 学習の基本パラメータ\n",
        "os.environ[\"SFT_SEED\"] = \"3407\"\n",
        "os.environ[\"SFT_VAL_RATIO\"] = \"0.05\"\n",
        "os.environ[\"SFT_MAX_SEQ_LEN\"] = \"512\"\n",
        "\n",
        "# 3. LoRA (アダプタ) 設定\n",
        "os.environ[\"SFT_LORA_R\"] = \"64\"\n",
        "os.environ[\"SFT_LORA_ALPHA\"] = \"128\"\n",
        "os.environ[\"SFT_LORA_DROPOUT\"] = \"0\"\n",
        "os.environ[\"SFT_LORA_TARGET_MODULES\"] = \"q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj\"\n",
        "\n",
        "# 4. ハイパーパラメータ\n",
        "os.environ[\"SFT_EPOCHS\"] = \"1\"\n",
        "os.environ[\"SFT_PER_DEVICE_TRAIN_BS\"] = \"2\"\n",
        "os.environ[\"SFT_PER_DEVICE_EVAL_BS\"] = \"2\"\n",
        "os.environ[\"SFT_GRAD_ACCUM\"] = \"8\"\n",
        "#os.environ[\"SFT_LR\"] = \"1e-6\" #Default\n",
        "os.environ[\"SFT_LR\"] = \"1e-4\"\n",
        "os.environ[\"SFT_WARMUP_RATIO\"] = \"0.1\"\n",
        "os.environ[\"SFT_WEIGHT_DECAY\"] = \"0.05\"\n",
        "\n",
        "# 5. ステップ・保存設定\n",
        "os.environ[\"SFT_MAX_STEPS\"] = \"-1\" # -1でエポックベース。動作確認時は 10 などに。\n",
        "os.environ[\"SFT_LOGGING_STEPS\"] = \"10\"\n",
        "os.environ[\"SFT_EVAL_STEPS\"] = \"50\"\n",
        "os.environ[\"SFT_SAVE_STEPS\"] = \"100\"\n",
        "os.environ[\"SFT_SAVE_TOTAL_LIMIT\"] = \"2\"\n",
        "\n",
        "# 6. 特殊学習設定 (CoTマスク・アップサンプリング)\n",
        "os.environ[\"SFT_MASK_COT\"] = \"1\" # \"1\" で有効, \"0\" で無効\n",
        "os.environ[\"SFT_OUTPUT_MARKERS\"] = \"Output:,OUTPUT:,Final:,Answer:,Result:,Response:\"\n",
        "os.environ[\"SFT_OUTPUT_LEARN_MODE\"] = \"after_marker\" # \"after_marker\" または \"from_marker\"\n",
        "os.environ[\"SFT_USE_UPSAMPLING\"] = \"1\" # \"1\" で有効, \"0\" で無効  # データ2-1,2-2,2-3 専用\n",
        "os.environ[\"SFT_UPSAMPLE_RULES\"] = '{\"xml_to_yaml\": 2.0}' # 例: '{\"json_to_xml\": 1.8, \"text_to_yaml\": 1.6}' # データ2-1,2-2,2-3 専用\n",
        "\n",
        "print(\"環境変数の設定が完了しました。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: 学習成果物の確認と、LoRAアダプタのhuggingfaceへのアップロード\n",
        "学習後、OUT_LORA_DIR に以下が保存されます（最低限）ので、確認してください。\n",
        "- adapter_config.json\n",
        "- adapter_model.safetensors（または adapter_model.bin）\n",
        "- tokenizer 関連ファイル\n",
        "<br>\n",
        "\n",
        "下記に従って\"README.md\"を記載してから、HuggingFaceにアダプタアップロードを実行してください。"
      ],
      "metadata": {
        "id": "nVAg0vIdVLg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ① README.md の正しい書き方\n",
        "\n",
        "#### README.md の役割（最重要）\n",
        "\n",
        "Hugging Face では **README.md = モデルカード**です。\n",
        "「このLoRAは何を学習し、どう使い、何に注意すべきか」を **第三者が再利用できる水準で説明する義務**があります。\n",
        "\n",
        "README が不十分なモデルは、\n",
        "\n",
        "* OSSとして不適切\n",
        "* 学習内容が不透明\n",
        "* ライセンス違反リスクあり\n",
        "  と評価されます。\n",
        "\n",
        "---\n",
        "\n",
        "#### 必須構成（この順で書くこと）\n",
        "\n",
        "##### 1. YAMLメタデータ（必須）\n",
        "\n",
        "```yaml\n",
        "---\n",
        "base_model: Qwen/Qwen3-4B-Instruct-2507\n",
        "datasets:\n",
        "- u-10bei/structured_data_with_cot_dataset_512_v2\n",
        "language:\n",
        "- en\n",
        "license: Apache-2.0\n",
        "library_name: peft\n",
        "pipeline_tag: text-generation\n",
        "tags:\n",
        "- qlora\n",
        "- lora\n",
        "- structured-output\n",
        "---\n",
        "```\n",
        "\n",
        "**理由**\n",
        "\n",
        "* HF検索・分類・再現性に必須\n",
        "* 無いと「壊れたモデルカード」扱いになる\n",
        "\n",
        "---\n",
        "\n",
        "##### 2. モデル概要（What）\n",
        "\n",
        "```md\n",
        "# qwen3-4b-structured-output-lora\n",
        "\n",
        "This repository provides a **LoRA adapter** fine-tuned from\n",
        "**Qwen3-4B-Instruct-2507** using **QLoRA (4-bit, Unsloth)**.\n",
        "\n",
        "This repository contains **LoRA adapter weights only**.\n",
        "The base model must be loaded separately.\n",
        "```\n",
        "\n",
        "**必須ポイント**\n",
        "\n",
        "* 「LoRAアダプタのみ」であることを明記\n",
        "* ベースモデル名を明示\n",
        "\n",
        "---\n",
        "\n",
        "##### 3. 学習目的・設計思想（Why）\n",
        "\n",
        "```md\n",
        "## Training Objective\n",
        "\n",
        "This adapter is trained to improve **structured output accuracy**\n",
        "(JSON / YAML / XML / TOML / CSV).\n",
        "\n",
        "Loss is applied only to the final assistant output,\n",
        "while intermediate reasoning (Chain-of-Thought) is masked.\n",
        "```\n",
        "\n",
        "**今回の講座では特に重要**\n",
        "\n",
        "* assistant-only loss\n",
        "* CoT mask（Output: 以降のみ学習）\n",
        "\n",
        "---\n",
        "\n",
        "##### 4. 学習設定（How）\n",
        "\n",
        "```md\n",
        "## Training Configuration\n",
        "\n",
        "- Base model: Qwen3-4B-Instruct-2507\n",
        "- Method: QLoRA (4-bit)\n",
        "- Max sequence length: 512\n",
        "- Epochs: 1\n",
        "- Learning rate: 1e-6\n",
        "- LoRA: r=64, alpha=128\n",
        "```\n",
        "\n",
        "**再現性のため必須**\n",
        "\n",
        "---\n",
        "\n",
        "##### 5. 使用方法（How to use）\n",
        "\n",
        "````md\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "base = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "adapter = \"your_id/your-repo\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, adapter)\n",
        "````\n",
        "\n",
        "````\n",
        "\n",
        "---\n",
        "\n",
        "##### 6. データセット・ライセンス注意（必須・重要）\n",
        "```md\n",
        "## Sources & Terms (IMPORTANT)\n",
        "\n",
        "Training data: u-10bei/structured_data_with_cot_dataset_512_v2\n",
        "\n",
        "Dataset License: MIT License. This dataset is used and distributed under the terms of the MIT License.\n",
        "Compliance: Users must comply with the MIT license (including copyright notice) and the base model's original terms of use.\n",
        "````\n",
        "---\n",
        "##### 実行コードの見本\n",
        "\n",
        "- 【課題】最低限、モデルタイトルの欄は、必ず自身で書き込んで下さい。\n",
        "- 使用データセットを変更した場合には、\"Dataset License\",\"Compliance\" 欄も適切な形に書き換えてください。"
      ],
      "metadata": {
        "id": "t0AyjusDD2od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# README.md（モデルカード）を OUT_LORA_DIR に生成\n",
        "# -----------------------------\n",
        "# 学習完了後に実行し、Hugging Face の README.md（モデルカード）を生成\n",
        "# ベースモデル名・データセット名・学習ハイパーパラメータはコードの変数から自動同期\n",
        "\n",
        "import os\n",
        "\n",
        "os.makedirs(OUT_LORA_DIR, exist_ok=True)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 補助関数の定義\n",
        "# ------------------------------------------------------------------\n",
        "def _s(x, default=\"\"):\n",
        "    try:\n",
        "        v = str(x)\n",
        "        return v if v.strip() else default\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "def _fmt_lr(x) -> str:\n",
        "    \"\"\"\n",
        "    Learning Rate の表記を整えるための関数。\n",
        "\n",
        "    - 数値として解釈できる場合：\n",
        "      指数表記（例: 1e-6）に整形する\n",
        "    - 数値として解釈できない場合：\n",
        "      元の値をそのまま文字列として出力する\n",
        "      （誤った値を生成しないための安全策）\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return f\"{float(x):.0e}\"\n",
        "    except Exception:\n",
        "        return _s(x, \"\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 学習コードの変数から値を取得（README と自動同期）\n",
        "# ------------------------------------------------------------------\n",
        "base_model_id = _s(BASE_MODEL_ID, \"Qwen/Qwen3-4B-Instruct-2507\")\n",
        "dataset_id = _s(DATASET_ID, \"https://huggingface.co/datasets/u-10bei/structured_data_with_cot_dataset_512_v2\")\n",
        "\n",
        "max_seq_len = int(MAX_SEQ_LEN)\n",
        "epochs = int(NUM_TRAIN_EPOCHS)\n",
        "lr_str = _fmt_lr(LR)\n",
        "\n",
        "lora_r = int(LORA_R)\n",
        "lora_alpha = int(LORA_ALPHA)\n",
        "\n",
        "# NOTE:\n",
        "# - YAML front matter の license は\n",
        "#   「この LoRA アダプタ（リポジトリ）のライセンス表明」を意味する。\n",
        "# - 必要に応じて環境変数で差し替え可能。\n",
        "repo_license = os.environ.get(\"SFT_REPO_LICENSE\", \"apache-2.0\")\n",
        "\n",
        "# README 内に記載するモデルタイトル\n",
        "# 変更したい場合は README.md を手書きで調整\n",
        "#title_line = \"＜【課題】ここは自分で記入して下さい＞\" #例： qwen3-4b-structured-output-lora\n",
        "title_line = \"test_qwen3-4b-structured-output-lora\" #例： qwen3-4b-structured-output-lora\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# README.md 本文の生成\n",
        "# （説明テキストに準拠し、変数部分のみを自動置換）\n",
        "# ------------------------------------------------------------------\n",
        "readme_md = f\"\"\"---\n",
        "base_model: {base_model_id}\n",
        "datasets:\n",
        "- {dataset_id}\n",
        "language:\n",
        "- en\n",
        "license: {repo_license}\n",
        "library_name: peft\n",
        "pipeline_tag: text-generation\n",
        "tags:\n",
        "- qlora\n",
        "- lora\n",
        "- structured-output\n",
        "---\n",
        "\n",
        "{title_line}\n",
        "\n",
        "This repository provides a **LoRA adapter** fine-tuned from\n",
        "**{base_model_id}** using **QLoRA (4-bit, Unsloth)**.\n",
        "\n",
        "This repository contains **LoRA adapter weights only**.\n",
        "The base model must be loaded separately.\n",
        "\n",
        "## Training Objective\n",
        "\n",
        "This adapter is trained to improve **structured output accuracy**\n",
        "(JSON / YAML / XML / TOML / CSV).\n",
        "\n",
        "Loss is applied only to the final assistant output,\n",
        "while intermediate reasoning (Chain-of-Thought) is masked.\n",
        "\n",
        "## Training Configuration\n",
        "\n",
        "- Base model: {base_model_id}\n",
        "- Method: QLoRA (4-bit)\n",
        "- Max sequence length: {max_seq_len}\n",
        "- Epochs: {epochs}\n",
        "- Learning rate: {lr_str}\n",
        "- LoRA: r={lora_r}, alpha={lora_alpha}\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "base = \"{base_model_id}\"\n",
        "adapter = \"rokugatsu/LLM2025\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, adapter)\n",
        "```\n",
        "\n",
        "## Sources & Terms (IMPORTANT)\n",
        "\n",
        "Training data: {dataset_id}\n",
        "\n",
        "Dataset License: MIT License. This dataset is used and distributed under the terms of the MIT License.\n",
        "Compliance: Users must comply with the MIT license (including copyright notice) and the base model's original terms of use.\n",
        "\"\"\"\n",
        "# ------------------------------------------------------------------\n",
        "# README.md の書き込み\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "readme_path = os.path.join(OUT_LORA_DIR, \"README.md\")\n",
        "with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme_md)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 動作確認\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "assert os.path.exists(readme_path), \"README.md was not written.\"\n",
        "assert readme_md.lstrip().startswith(\"---\\n\"), (\n",
        "    \"README.md must start with YAML front matter.\"\n",
        ")\n",
        "# 修正: 先頭の --- は改行なしで始まるため count(\"\\n---\\n\") には含まれない。\n",
        "# そのため、閉じタグの分として 1回以上あればOKとする。\n",
        "assert readme_md.count(\"\\n---\\n\") >= 1, (\n",
        "    \"YAML front matter must be closed properly.\"\n",
        ")\n",
        "\n",
        "print(f\"[INFO] README.md written to: {readme_path}\")\n",
        "print(\"[INFO] Preview (first 30 lines):\")\n",
        "for i, line in enumerate(readme_md.splitlines()[:30], start=1):\n",
        "    print(f\"{i:02d}: {line}\")"
      ],
      "metadata": {
        "id": "FhZ-2hZBSSSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36acadf3-a257-462d-d126-b1a41da7b039"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] README.md written to: /content/lora_structeval_t_qwen3_4b/README.md\n",
            "[INFO] Preview (first 30 lines):\n",
            "01: ---\n",
            "02: base_model: Qwen/Qwen3-4B-Instruct-2507\n",
            "03: datasets:\n",
            "04: - u-10bei/structured_data_with_cot_dataset_512_v2\n",
            "05: language:\n",
            "06: - en\n",
            "07: license: apache-2.0\n",
            "08: library_name: peft\n",
            "09: pipeline_tag: text-generation\n",
            "10: tags:\n",
            "11: - qlora\n",
            "12: - lora\n",
            "13: - structured-output\n",
            "14: ---\n",
            "15: \n",
            "16: test_qwen3-4b-structured-output-lora\n",
            "17: \n",
            "18: This repository provides a **LoRA adapter** fine-tuned from\n",
            "19: **Qwen/Qwen3-4B-Instruct-2507** using **QLoRA (4-bit, Unsloth)**.\n",
            "20: \n",
            "21: This repository contains **LoRA adapter weights only**.\n",
            "22: The base model must be loaded separately.\n",
            "23: \n",
            "24: ## Training Objective\n",
            "25: \n",
            "26: This adapter is trained to improve **structured output accuracy**\n",
            "27: (JSON / YAML / XML / TOML / CSV).\n",
            "28: \n",
            "29: Loss is applied only to the final assistant output,\n",
            "30: while intermediate reasoning (Chain-of-Thought) is masked.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### ② README.md の HF アップロードコード\n",
        "\n",
        "以下は **README.md を自動生成しません**。\n",
        "\n",
        "* 直前のコードを参照してREADME.md 完成させ、 OUT_LORA_DIR に保存してから実行してください。\n",
        "* アップロード対象として README.md を必須化\n",
        "* README.md が存在しない場合 → **エラー**\n",
        "---"
      ],
      "metadata": {
        "id": "1yne5up9W4OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3) LoRAアダプターをHugging Faceへアップロード (作成済みのREADMEを含む)\n",
        "# ============================================================\n",
        "\n",
        "import fnmatch\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Hugging Face APIの操作用インスタンスを作成\n",
        "api = HfApi()\n",
        "\n",
        "# 各種パスや設定の準備\n",
        "LORA_SAVE_DIR = Path(OUT_LORA_DIR)  # 学習済みモデルが保存されているディレクトリ\n",
        "HF_REPO_ID    = _getenv(\"HF_REPO_ID\", \"rokugatsu/LLM2025\")  # アップロード先のレポジトリID\n",
        "\n",
        "# 非公開設定の確認（環境変数が '1' または 'true' ならプライベート設定にする）\n",
        "PRIVATE       = _getenv(\"HF_PRIVATE\", \"1\") in (\"1\",\"true\",\"True\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3.1) 必須ファイルの存在確認\n",
        "# -----------------------------\n",
        "# アップロードに最低限必要なファイルを定義します\n",
        "required_files = {\n",
        "    \"adapter_config.json\", # LoRAの設定ファイル\n",
        "    \"README.md\",           # 受講生が作成した解説文書\n",
        "}\n",
        "\n",
        "# 保存ディレクトリにあるファイル名のリストを取得\n",
        "present = {p.name for p in LORA_SAVE_DIR.iterdir() if p.is_file()}\n",
        "\n",
        "# 足りないファイルをリストアップ\n",
        "missing = [f for f in required_files if f not in present]\n",
        "\n",
        "# モデル本体（adapter_model.safetensors または .bin）が存在するか確認\n",
        "if not any(f.startswith(\"adapter_model.\") for f in present):\n",
        "    missing.append(\"adapter_model.(safetensors|bin)\")\n",
        "\n",
        "# 必須ファイルが欠けている場合は、エラーを表示して処理を中断します\n",
        "if missing:\n",
        "    raise RuntimeError(\n",
        "        \"アップロードを中止しました。\\n\"\n",
        "        \"以下の必須ファイルが見つかりません:\\n\"\n",
        "        + \"\\n\".join(f\"- {m}\" for m in missing) +\n",
        "        \"\\n\\nアップロード前に、README.md を手書きで作成し保存してください。\"\n",
        "    )\n",
        "\n",
        "print(\"✅ 必須ファイルの確認が完了しました。\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3.2) アップロード対象の選別（ホワイトリスト）\n",
        "# -----------------------------\n",
        "# 不要な一時ファイルなどをアップロードしないよう、許可するファイル形式を指定します\n",
        "ALLOW_PATTERNS = [\n",
        "    \"README.md\",\n",
        "    \"adapter_config.json\",\n",
        "    \"adapter_model.*\",\n",
        "    \"tokenizer.*\",\n",
        "    \"special_tokens_map.json\",\n",
        "    \"*.json\",\n",
        "]\n",
        "\n",
        "def is_allowed(name: str) -> bool:\n",
        "    \"\"\"ファイル名が許可パターンに一致するか判定する関数\"\"\"\n",
        "    return any(fnmatch.fnmatch(name, pat) for pat in ALLOW_PATTERNS)\n",
        "\n",
        "# アップロード用の一時フォルダ（ステージング領域）を作成\n",
        "STAGE_DIR = Path(\"/content/hf_upload_stage\")\n",
        "\n",
        "if STAGE_DIR.exists():\n",
        "    shutil.rmtree(STAGE_DIR) # 既存のフォルダがあれば一旦削除\n",
        "STAGE_DIR.mkdir(parents=True)\n",
        "\n",
        "# 許可されたファイルだけを一時フォルダにコピー\n",
        "for p in LORA_SAVE_DIR.iterdir():\n",
        "    if p.is_file() and is_allowed(p.name):\n",
        "        (STAGE_DIR / p.name).write_bytes(p.read_bytes())\n",
        "\n",
        "print(\"📦 アップロード対象ファイル:\", [p.name for p in STAGE_DIR.iterdir()])\n",
        "\n",
        "# -----------------------------\n",
        "# 3.3) リポジトリ作成とアップロード\n",
        "# -----------------------------\n",
        "\n",
        "# Hugging Face上にリポジトリを作成（既に存在していてもOK）\n",
        "api.create_repo(\n",
        "    repo_id=HF_REPO_ID,\n",
        "    repo_type=\"model\",\n",
        "    exist_ok=True,\n",
        "    private=PRIVATE,\n",
        ")\n",
        "\n",
        "# 一時フォルダの内容をまるごとアップロード\n",
        "api.upload_folder(\n",
        "    folder_path=str(STAGE_DIR),\n",
        "    repo_id=HF_REPO_ID,\n",
        "    repo_type=\"model\",\n",
        "    commit_message=\"Upload LoRA adapter (README written by author)\",\n",
        ")\n",
        "\n",
        "print(\"✅ アップロードが正常に完了しました。\")\n",
        "print(f\"URL: https://huggingface.co/{HF_REPO_ID}\")"
      ],
      "metadata": {
        "id": "7bLNMxfZOwIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239,
          "referenced_widgets": [
            "d1bc8aaa7bf846e4b020aa59501894f2",
            "50d02cf203e34dc7a2ebc9a8f580f1a1",
            "246aee554db34dc8a86212c9e77852e1",
            "05c63df112444b0eb2b20989e6161f9e",
            "45dff47faef64f24ac5fce0f82401155",
            "a58677a754284a7daca3b2a2918b9ccb",
            "efc43c4de1db4f2e9835b177e73de74d",
            "669662156b4345019fb6b91c0a5b6920",
            "b0aed939fb604203a240be4a771aba8f",
            "9714da820f72400b8168270abd7a8a3c",
            "b2e9b2b0a4394797a98e060a2e00bf20",
            "3dbd5337cedb4c4f949bcdd13fa9f9ac",
            "3b3781a1ced0472f9b5519af9f9369a6",
            "31ecfd13c34e401593114ae25bb36ad8",
            "38e9f29b06864ae29b7912c3066a2b92",
            "3c9539ff41274436b6ba9b1cbd8a6025",
            "6ad2350bb9dc495fac40bf057a2264e4",
            "edba282cc2104b469458d52472bf8946",
            "709f37b5f25842988485732b92cbdf3f",
            "a30308b433414158827f01ef2752e08d",
            "3e35a5c272ac493fb7e4e4e9c524315d",
            "186d81ba39dc4b4cb27b665c9882de36",
            "14c1686cbd4d4564a9dbff4899411135",
            "5e928d2b206647998d2f389b3581c6fc",
            "f57af96717944e2783ebd63adc94acdf",
            "814a03905f044c03ac14767a0fa747c6",
            "8ab0014db62c4ef4a87974d70e6b0bfd",
            "82a16667ca6045edb144d65ec146594e",
            "f83fb8df5456462d96dba8830672871f",
            "7fdb3cb464c84d7b9c8caa24b1cd1cf9",
            "1c24a0e5f9f644f29f73fc3d6de5a74c",
            "659048492a0a43aab019da18cc0db4d2",
            "1daec5231e9c4592b06f0a76592ea1e4",
            "c1b6a8ebd7624825b20512aa048ef995",
            "f4e2f8dc2c49478e885a6a2afad0208a",
            "6457beeaee2d4b6786f7eec2ad5fd64c",
            "e4cba8d2f14940cda291cbfcf595b469",
            "9d0e936cf87e48a18f9c60041a927add",
            "acc53ca9e83a4e57ab58ca26ae865c75",
            "b32c20d607d5477fa6b4e96deecc1b7e",
            "0b02ee66f38d41e8970acf63d826a473",
            "97a59712f8784a67aa7d29dbe1c40393",
            "a8759e79213b4c4a874202810a4194f4",
            "d5137b2f307b46b3bbb4c8b028b56791"
          ]
        },
        "outputId": "c15f2a34-37f2-4634-b2e9-9877557366f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 必須ファイルの確認が完了しました。\n",
            "📦 アップロード対象ファイル: ['adapter_config.json', 'README.md', 'tokenizer_config.json', 'adapter_model.safetensors', 'vocab.json', 'special_tokens_map.json', 'added_tokens.json', 'tokenizer.json']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1bc8aaa7bf846e4b020aa59501894f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dbd5337cedb4c4f949bcdd13fa9f9ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...load_stage/tokenizer.json: 100%|##########| 11.4MB / 11.4MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14c1686cbd4d4564a9dbff4899411135"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...adapter_model.safetensors:   0%|          | 61.5kB /  529MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1b6a8ebd7624825b20512aa048ef995"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ アップロードが正常に完了しました。\n",
            "URL: https://huggingface.co/rokugatsu/LLM2025\n"
          ]
        }
      ]
    }
  ]
}